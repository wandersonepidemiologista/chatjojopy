import streamlit as st
from langchain.llms import HuggingFaceHub
from langchain.chains.question_answering import load_qa_chain
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA
from dotenv import load_dotenv
import os
import random

# ğŸ” Carrega token Hugging Face
load_dotenv()
hf_token = os.getenv("HUGGINGFACEHUB_API_TOKEN")

# ğŸ¤– Configura modelo de linguagem
llm = HuggingFaceHub(
    repo_id="google/flan-t5-base",
    model_kwargs={"temperature": 0.5, "max_length": 512},
    huggingfacehub_api_token=hf_token,
    task="text2text-generation"
)

# ğŸŒ ConfiguraÃ§Ã£o da interface
st.set_page_config(page_title="ChatJoJoPy com HF", layout="wide")
st.title("ğŸ¤– ChatJoJoPy â€” EmergÃªncias em SaÃºde PÃºblica")

# ğŸ“‚ Carrega os documentos
@st.cache_resource
def carregar_base():
    documentos = []
    pasta = "documentos"
    for arquivo in os.listdir(pasta):
        if arquivo.endswith(".pdf"):
            caminho = os.path.join(pasta, arquivo)
            loader = PyPDFLoader(caminho)
            documentos.extend(loader.load())
    splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    chunks = splitter.split_documents(documentos)
    embeddings = HuggingFaceEmbeddings()
    return FAISS.from_documents(chunks, embeddings)

db = carregar_base()
retriever = db.as_retriever()
rag = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

# ğŸ’¡ Perguntas quebra-gelo
perguntas_exemplo = [
    "O que Ã© uma emergÃªncia em saÃºde pÃºblica?",
    "Quais sÃ£o os critÃ©rios para ativar o plano de resposta?",
    "Quem deve ser acionado primeiro em caso de surto?",
    "Quais fases compÃµem um plano de contingÃªncia?",
    "Como a APS atua em situaÃ§Ãµes de desastre?",
    "Quais os principais indicadores de prontidÃ£o municipal?",
    "Como se organiza o fluxo de resposta em campo?",
    "O que diferencia uma emergÃªncia local de uma nacional?",
    "Como integrar a atenÃ§Ã£o primÃ¡ria em emergÃªncias?",
    "Quais documentos norteiam a resposta a desastres quÃ­micos?"
]

sugestao = random.choice(perguntas_exemplo)
st.markdown("### ğŸ’¡ **Exemplo de pergunta** (quebra-gelo):")
st.info(f"ğŸ’¬ {sugestao}")

if "pergunta" not in st.session_state:
    st.session_state.pergunta = ""

if st.button("ğŸ‘ˆ Usar essa pergunta"):
    st.session_state.pergunta = sugestao

# ğŸ§  Campo de entrada com sugestÃ£o
pergunta = st.text_input("Digite sua pergunta:", value=st.session_state.pergunta, key="pergunta")

# ğŸ“Œ Resultado
if pergunta:
    resposta = rag.run(pergunta)
    st.markdown("### ğŸ“Œ Resposta:")
    st.write(resposta)
